{
 "metadata": {
  "name": "",
  "signature": "sha256:0009c1c31005d379de66a79885cda904d24850ae37a03453fe90b16a9e491a7f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import numpy as np\n",
      "from sklearn import linear_model\n",
      "from os import mkdir\n",
      "import string\n",
      "import random\n",
      "import operator\n",
      "from os import path\n",
      "import pandas as pd\n",
      "import urllib\n",
      "import zipfile\n",
      "import sys\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib\n",
      "matplotlib.style.use('ggplot')\n",
      "\n",
      "#11,12,13,14\n",
      "\n",
      "filename = 'household_power_consumption'\n",
      "na_values = ['?', np.nan]\n",
      "fields = ['Date', 'Time', 'Global_active_power']\n",
      "df = pd.read_csv(filename + '.txt', sep=';', nrows=200000,\n",
      "na_values=na_values, usecols=fields)\n",
      "#print df[1:9].values\n",
      "#print type(df.iloc[9])\n",
      "#print df.dtypes\n",
      "print len(df)\n",
      "print len(df[df.Global_active_power.isnull() == True])\n",
      "df = df[df.Global_active_power.isnull() != True]\n",
      "print len(df)\n",
      "df.Date = pd.to_datetime(df.Date)\n",
      "df.set_index([\"Date\"])\n",
      "print df.head()\n",
      "#df.groupby(['Date'])['Global_active_power'].mean()*60*24\n",
      "\n",
      "start = pd.datetime(2007, 1, 1)\n",
      "end = pd.datetime(2007, 4, 30)\n",
      "\n",
      "#start = '2006-12-16'\n",
      "#end = '2006-12-18'\n",
      "\n",
      "# print df.groupby(['Date'])['Global_active_power'].mean()\n",
      "#print pd.to_datetime(df.head().Date, dayfirst = True)\n",
      "#print pd.to_datetime(df.head().Date + \" \" + df.head().Time, dayfirst = True)\n",
      "k = df[(df.Date >= start) & (df.Date <= end)].groupby(['Date'])['Global_active_power'].mean()\n",
      "plt.figure()\n",
      "k.plot()\n",
      "plt.show()\n",
      "#df.set_index('Times',pd.to_datetime(df.head().Date + \" \" + df.head().Time, dayfirst = True))\n",
      "\n",
      "\n",
      "#ex15, 16\n",
      "filename = 'C:\\Users\\guoli_000\\Desktop\\TGSTAID011249'  #nrows=20, na_values=na_values,\n",
      "na_values = ['-9999', '']\n",
      "fields = ['DATE', 'TG']\n",
      "dt = pd.read_csv(filename + '.txt', sep=',', na_values=na_values, usecols=fields)\n",
      "# dt = pd.read_csv(filename + '.txt', sep=',',nrows=2000, na_values=na_values, usecols=fields)\n",
      "print len(dt)\n",
      "print len(dt[dt.TG.isnull() == True])\n",
      "dt = dt[dt.TG.isnull() != True]\n",
      "dt.TG = dt.TG/10.0\n",
      "# print dt.DATE[1:10]\n",
      "dt.DATE = pd.to_datetime(dt.DATE, format='%Y%m%d', errors='ignore')\n",
      "dt.set_index([\"DATE\"])\n",
      "\n",
      "print len(dt)\n",
      "print dt[1:10]\n",
      "\n",
      "start = pd.datetime(2007, 1, 1)\n",
      "end = pd.datetime(2007, 4, 30)\n",
      "t = dt[(dt.DATE >= start) & (dt.DATE <= end)]\n",
      "\n",
      "print t[1:10]\n",
      "\n",
      "filename = 'household_power_consumption'\n",
      "na_values = ['?', np.nan]\n",
      "fields = ['Date', 'Time', 'Global_active_power']\n",
      "df = pd.read_csv(filename + '.txt', sep=';', nrows=200000,na_values=na_values, usecols=fields)\n",
      "# print len(df)\n",
      "# print len(df[df.Global_active_power.isnull() == True])\n",
      "df = df[df.Global_active_power.isnull() != True]\n",
      "# print len(df)\n",
      "df.Date = pd.to_datetime(df.Date)\n",
      "df.set_index([\"Date\"])\n",
      "# print df.head()\n",
      "k = df[(df.Date >= start) & (df.Date <= end)].groupby(['Date'])['Global_active_power'].mean()\n",
      "\n",
      "ax = t.plot('DATE', 'TG')\n",
      "k.plot(ax=ax)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "File household_power_consumption.txt does not exist",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-ec1c6b3f3bec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Global_active_power'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m df = pd.read_csv(filename + '.txt', sep=';', nrows=200000,\n\u001b[0;32m---> 23\u001b[0;31m na_values=na_values, usecols=fields)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m#print df[1:9].values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#print type(df.iloc[9])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m    450\u001b[0m                     infer_datetime_format=infer_datetime_format)\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3218)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:5594)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: File household_power_consumption.txt does not exist"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "%cd /cal/homes/lguo/Downloads"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/cal/homes/lguo/Downloads\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import numpy as np\n",
      "from sklearn import linear_model\n",
      "from os import mkdir\n",
      "\n",
      "# ex1\n",
      "def nextpower(num):\n",
      "    num = num**2\n",
      "    if type(num) != int:\n",
      "        num = \"% d\" % num\n",
      "    return num\n",
      "\n",
      "print nextpower(1.6)\n",
      "\n",
      "#ex3\n",
      "def disPi9(num):\n",
      "    return \"%.9f\" % num\n",
      "\n",
      "print disPi9(math.pi)\n",
      "\n",
      "#ex4\n",
      "def countLetter(str):\n",
      "    res = {}\n",
      "    if len(str)<1:\n",
      "        return str\n",
      "    for i in str:\n",
      "        if i in res:\n",
      "            res[i] = res[i] + 1\n",
      "        else:\n",
      "            if i != ' ':                \n",
      "                res[i] = 1\n",
      "            else: continue\n",
      "    return res\n",
      "print countLetter(\"HelLo WorLd!!\")\n",
      "\n",
      "#ex5\n",
      "def cesarCode(index):\n",
      "    let = list(string.lowercase)\n",
      "    random.shuffle(let)\n",
      "    shiftLet = np.roll(let,index)\n",
      "    # shiftLet = let[-index:]+let[:-index] # !\uff01\uff01 [-4:] => -4 -3 -2 -1; [: -4] => 0, 1, 2, ... sauf les derniers quatre elements\n",
      "    return dict(zip(let,shiftLet)), dict(zip(shiftLet,let))\n",
      "\n",
      "a,b = cesarCode(4)\n",
      "print a\n",
      "print b\n",
      "\n",
      "#ex6\n",
      "N = 10**7\n",
      "index = np.array(range(1,N))\n",
      "index = 4 * (index * index) / (4.0 * (index * index) -1)\n",
      "print np.prod(index)\n",
      "\n",
      "#ex7\n",
      "def quicksort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        left = []\n",
      "        right = []\n",
      "        middle = []\n",
      "        middle = (arr[0])\n",
      "        for i in arr[1:]:\n",
      "            if i<middle:\n",
      "                left.append(i)\n",
      "            else:\n",
      "                if i>=middle:\n",
      "                    right.append(i)\n",
      "                else: \n",
      "                    print \"error\"    \n",
      "        return reduce(operator.add,[quicksort(left), [middle], quicksort(right)])\n",
      "\n",
      "a= random.sample(range(2, 30), 10)\n",
      "print a\n",
      "print quicksort(a)\n",
      "\n",
      "#ex8\n",
      "row = 5\n",
      "col = 6\n",
      "M = np.random.uniform(-1, 1,(row, col))\n",
      "print M\n",
      "index = range(1,col)\n",
      "index.append(0)\n",
      "M = M - 2 * M[ : ,index]\n",
      "#print M[: ,index]\n",
      "print M\n",
      "\n",
      "M[M<0] = 0\n",
      "print M\n",
      "\n",
      "#ex9\n",
      "row = 5\n",
      "col = 2\n",
      "M = np.random.uniform(-1, 1,(row, col))\n",
      "print M\n",
      "\n",
      "M = np.matrix(M)\n",
      "\n",
      "M = M.T * M\n",
      "#print M[: ,index]\n",
      "print M\n",
      "\n",
      "print np.allclose(M, M.T, 10**-5)\n",
      "\n",
      "print np.diagonal(M)>0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn as sk\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from pathlib import Path\n",
      "import sys\n",
      "import random\n",
      "from os import listdir\n",
      "from os.path import isfile, join\n",
      "\n",
      "# totla of files: 20\n",
      "fileList=[\"8 Health Benefits of Apples\",\n",
      "#           \"An Apple a Day to Keep 5 Chronic Diseases Away?\", #?\n",
      "          \"Apple adds SIM-free iPhone 7 and 7 Plus option in the US\",\n",
      "#           \"Apple: From iPhones to iCars\", #:\n",
      "          \"Apple hires a Carnegie Mellon professor to improve its AI\",\n",
      "#           \"Apple in India: Forbidden fruit\",#:\n",
      "          \"Apple may ditch traditional USB ports on the MacBook Pro\",\n",
      "           \"Apple reportedly wants to use changeable E Ink keyboards\",#8\n",
      "#            \"Apples: Health Benefits, Facts, Research\",#:\n",
      "           \"Apples Ranked Second Highest for Antioxidant Activity\",\n",
      "           \"Apple suspends developer account over 'review fraud'\",\n",
      "           \"Apples winning streak is soon to end\",\n",
      "           \"Apple Watch Nike+ arrives on October 28th\",#5\n",
      "#             \"Are apple seeds poisonous?\", #?\n",
      "#             \"Bloomberg: Apple isn't building a car anymore\",#:\n",
      "           \"Corporate taxation Bruised Apple\",\n",
      "           \"Health benefits of apple\",\n",
      "           \"Smartphones Still ringing bells\",\n",
      "           \"Some People May Need to Eat Apples in Moderation\",\n",
      "            \"What's New and Beneficial About Apples\"]\n",
      "trainingRCS=['apple:fruits',\n",
      "#           'apple:fruits',\n",
      "          'apple:company',\n",
      "#           'apple:company',\n",
      "          'apple:company',\n",
      "#           'apple:company',\n",
      "          'apple:company',\n",
      "          'apple:company',#8\n",
      "#           'apple:fruits',\n",
      "          'apple:fruits',\n",
      "          'apple:company',\n",
      "          'apple:company',\n",
      "          'apple:company',#5\n",
      "#           'apple:fruits',\n",
      "#           'apple:company',\n",
      "          'apple:company',\n",
      "          'apple:fruits',\n",
      "          'apple:company',\n",
      "          'apple:fruits',\n",
      "          'apple:fruits']\n",
      "def readSets(path):\n",
      "    mypath='E:\\\\SD201-data-mining\\\\apple\\\\'\n",
      "    myfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
      "    for i in myfiles\n",
      "        readfile= open(i,'r')\n",
      "        trainingRC.append(trainingRCS[files.index(i)])\n",
      "        filesIN.append(readfile.read())\n",
      "        readfile.close()\n",
      "    return filesIN,trainingRC\n",
      "\n",
      "# def readSets(files):\n",
      "#     filesIN=[]\n",
      "#     trainingRC=[]\n",
      "#     for i in files:\n",
      "#         my_file = Path('E:\\\\SD201-data-mining\\\\apple\\\\'+ i)\n",
      "#         if my_file.is_file():\n",
      "#             readfile= open('E:\\\\SD201-data-mining\\\\apple\\\\','r')\n",
      "#             trainingRC.append(trainingRCS[files.index(i)])\n",
      "#             filesIN.append(readfile.read())\n",
      "#             readfile.close()\n",
      "#     return filesIN,trainingRC\n",
      "\n",
      "def randomFiles(files, count,trainingRC):\n",
      "    trainingCl=[]\n",
      "    testingCl=[]\n",
      "    trainingFiles=[]\n",
      "    testingFiles=[]\n",
      "    j=0\n",
      "    for i in range(0,count): \n",
      "        j=0\n",
      "        while(files[j] in trainingFiles):\n",
      "            j=random.randrange(0, 13) \n",
      "        trainingFiles.append(files[j])\n",
      "        trainingCl.append(trainingRC[j])\n",
      "                          \n",
      "    for i in range(0,len(files)):\n",
      "        if j not in trainingFiles:\n",
      "            testingFiles.append(files[i])\n",
      "            testingCl.append(trainingRC[i]) \n",
      "    return trainingFiles,testingFiles,trainingCl,testingCl\n",
      "trainingCl=[]\n",
      "testingCl=[]\n",
      "trainingFiles=[]\n",
      "testingFiles=[]\n",
      "trainingRC=[]\n",
      "\n",
      "appleFiles,trainingRC= readSets(fileList)\n",
      "\n",
      "resulstA=[]\n",
      "resulstK=[]\n",
      "maxres=0\n",
      "kmax=0\n",
      "stop_words=['and','or','for','with','.',',','the','then','end','is','to','in','it','or','.','this','which','of','a','an',\n",
      "            'if','as']\n",
      "for i in range(1,7): \n",
      "    trainingFiles,testingFiles,trainingCl,testingCl= randomFiles(appleFiles,9,trainingRC) \n",
      "#     count_vect = CountVectorizer(stop_words)\n",
      "#     print trainingFiles[1]\n",
      "    count_vect = CountVectorizer()\n",
      "    X_train_counts = count_vect.fit_transform(trainingFiles)\n",
      "    training=X_train_counts.toarray()\n",
      "    neigh = KNeighborsClassifier(n_neighbors=i)\n",
      "    neigh.fit(training,trainingCl)\n",
      "\n",
      "    X_testing_counts = count_vect.transform(testingFiles)\n",
      "    testing=X_testing_counts.toarray()\n",
      "\n",
      "    results=neigh.score(testing,testingCl)\n",
      "    resulstA.append(results)\n",
      "    resulstK.append(i)\n",
      "    if results>maxres: \n",
      "        maxres=results\n",
      "        kmax=i\n",
      "print \"maxres:\",maxres\n",
      "print \"kmax:\",kmax\n",
      "print 'k:', resulstK\n",
      "print 'Accuracy:',resulstA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read files(name) from a folder in windows\n",
      "from os import walk\n",
      "mypath='E:\\\\SD201-data-mining\\\\apple\\\\'\n",
      "f = []\n",
      "for (dirpath, dirnames, filenames) in walk(mypath):\n",
      "    f.extend(filenames)\n",
      "    break\n",
      "print 'filename:', f\n",
      "print dirpath\n",
      "print dirnames\n",
      "\n",
      "# from os import listdir\n",
      "# from os.path import isfile, join\n",
      "# mypath='E:\\\\SD201-data-mining\\\\apple\\\\'\n",
      "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
      "# print onlyfiles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}